
# coding: utf-8

# # 五目並べAI
# 
# ## 概要
# 
# AIはvalue_networkと盤面探索を組み合わせています。<br>
# value_networkは五目並べの盤面から、ゲームの情勢を判断するモデルです。<br>
# AIはvalue_networkにより次のすべての盤面の中から最も自分にとって優勢のものを選択し、打つ手を決定します。<br>

# In[4]:


import tensorflow as tf
import os


# ## CNN
# 
# value_networkはシンプルなCNNによって構成されています。<br>
# 盤面情報を画像として入力し、黒の勝率を出力します。<br>
# 
# 入力次元 - (Batch_size x size x size x channel)
# - Batch_size: 学習のミニバッチのサイズ（任意）
# - size: 盤面サイズ(デフォルト9)
# - channel: 2(黒と白)
# 
# 出力次元 - (1)

# In[7]:


size = 9


# In[5]:


def cnn(x):
    x_image = tf.reshape(x, [-1, size, size, 2])    # [None, size, size, 2]
    conv1 = tf.layers.conv2d(x_image, 128, (3, 3), padding='same',
                             activation=tf.nn.relu)    # [None, size, size, 128]
    conv2 = tf.layers.conv2d(conv1, 128, (3, 3), padding='same',
                             activation=tf.nn.relu)    # [None, size, size, 128]
    pool_flat = tf.layers.flatten(conv2) # [None, size * size * 128]
    dense = tf.layers.dense(pool_flat, 64, activation=tf.nn.relu) # [None, 64]
    y = tf.layers.dense(dense, 1) # [None, 1]
    return y


# In[6]:


class value_network_model:
    def __init__(self, size=9, rate=1e-6):
        tf.reset_default_graph()
        self.x = tf.placeholder(tf.float32, (None, size, size, 2))
        self.t = tf.placeholder(tf.float32, (None, 1))
        self.y = cnn(self.x)
        self.trail = 0
        self.model_path = './model/'
        self.logs_path = './log/'
        self.saver = tf.train.Saver()
        self.cost = tf.reduce_mean(tf.square(self.y - self.t))
        self.optimizer = tf.train.AdamOptimizer(rate).minimize(self.cost)
        self.train_summary_loss = tf.summary.scalar('train_loss', self.cost)
        self.saver = tf.train.Saver()
        self.summary_writer = tf.summary.FileWriter(
            self.logs_path, graph=tf.get_default_graph())
        self.sess = tf.Session()
        self.sess.run(tf.global_variables_initializer())
        if not os.path.exists(self.model_path):
            os.mkdir(self.model_path)
        else:
            self.load()

    def load(self):
        self.saver.restore(self.sess, self.model_path)

    def new_logs(self):
        if os.path.exists(self.logs_path):
            shutil.rmtree(self.logs_path)
        os.mkdir(self.logs_path)

    # モデル予測値の出力
    def out(self, X):
        return self.y.eval(feed_dict={self.x: X}, session=self.sess)

    # 最適化
    def optimize(self, X, T):
        _, cost, summary_loss = self.sess.run(
            [self.optimizer, self.cost, self.train_summary_loss], feed_dict={self.x: X, self.t: T})
        # ログの保存
        self.summary_writer.add_summary(summary_loss, self.trail)
        self.trail += 1
        # モデルの保存
        self.saver.save(self.sess, self.model_path)
        return cost

